<blockquote>

!{width:512px;height:440px;}media/image1.png!

*Name of Student : İrfan Kaan ALGAN*

*ID Number 2328599*

*Name of Company : INNOVA Bilişim Çözümleri A.Ş*

*Project Title : Text Classification Date of Submission : 29/12/2021*

</blockquote>

h1(#abstract). ABSTRACT

<blockquote>

In this report, I will mention information and some specific problems with solutions throughout my summer internship. The main purpose of this internship was to create a model to solve a problem, learn how to program in Jupyter Notebook, get familiar with data manipulation and gain some knowledge about ML. I have created a model that collects complaints about a company and categorizes them. There are many models like stemmer, lemmatization and for English texts, I tried to create a text cleaning model for Turkish texts. Not only I have created a model, but also, I have improved myself about knowledge of Python and Machine Learning.

Unfortunately, I had no chance to work with a team, and I had to develop a program with a language that I did not have experience with. However, this situation helped me to improve my self&#45;learning, hard&#45;working, and problem&#45;solving skills.

*TABLE OF CONTENTS*

</blockquote>

"ABSTRACT 2":#abstract

bq. "TABLE OF FIGURES 4":#table-of-figures



<ol style="list-style-type: decimal;">
<li><p>"INNOVA BİLİŞİM ÇÖZÜMLERİ A.Ş 5":#innova-bi̇li̇şi̇m-çözümleri̇-a.ş</p></li>
<li><p>"INTRODUCTION 6":#introduction</p></li>
<li>bq. <p>"PROBLEM STATEMENT 6":#problem-statement</p>


<ol style="list-style-type: decimal;">
<li><p>"Labeling Data Manually 6":#labeling-data-manually</p>
<ol style="list-style-type: decimal;">
<li><p>"www.sikayetvar.com":http://www.sikayetvar.com/ "7":#_bookmark8</p></li>
</ol>
</li>
<li><p>"Building Database 8":#building-database</p>
<ol style="list-style-type: decimal;">
<li><p>"PostgreSQL 8":#postgresql</p></li>
<li><p>"Trained Data 9":#trained-data</p></li>
<li><p>"Test Data 9":#test-data</p></li>
<li><p>"Comparison Data 9":#comparison-data</p></li>
</ol>
</li>
<li>bq. <p>"Supervised Learning Algorithm 9":#supervised-learning-algorithm</p>


<ol style="list-style-type: decimal;">
<li><p>"Classification 9":#classification</p></li>
<li><p>"Text Pre&#45;Processing 10":#text-pre-processing</p></li>
<li><p>"Vectorization 13":#vectorization</p>
<ol style="list-style-type: decimal;">
<li><p>"Term Frequency&#45;Inverse Document Frequencies (tf&#45;idf) 13":#term-frequency-inverse-document-frequencies-tf-idf</p></li>
<li><p>"Word2Vec 13":#word2vec</p></li>
</ol>
</li>
<li><p>"ML Algorithm 14":#ml-algorithm</p>
<ol style="list-style-type: decimal;">
<li><p>"Logistic Regression 14":#logistic-regression</p>
<ol style="list-style-type: decimal;">
<li><p>"AUC (Area Under the Curve) 15":#auc-area-under-the-curve</p></li>
<li><p>"Precision 16":#precision</p></li>
<li>bq. <p>"Recall 16":#recall</p>

</li>
<li>bq. <p>"F1&#45;Score 16":#f1-score</p>

</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
</ol>
</li>
<li><p>"CONCLUSION 17":#conclusion</p></li>
<li><p>"REFERENCES 18":#references</p></li>
<li><p>"REMOTE INTERNSHIP APPENDIX FORM 19":#remote-internship-appendix-form</p></li>
</ol>

h1(#table-of-figures). TABLE OF FIGURES

<blockquote>

<em>"website for labeling   7":#_bookmark6 "w":#_bookmark9"ww.sikayetvar.com":http://www.sikayetvar.com/ "Türk Telekom page   7":#_bookmark9 "Installing PostgreSQL library   8":#_bookmark13 "Taking data from database   8":#_bookmark15 "Saving data to data frame   8":#_bookmark17 "Classification graph   9":#_bookmark24 "Separated data   10":#_bookmark26 "Implementing Zemberek library   11":#_bookmark29 "Implementing stop word data   11":#_bookmark31 "Preprocessing functions   11":#_bookmark33 "Cleaned text   12":#_bookmark35</em>

<em>"Splitting datasets   13":#_bookmark40 "Tf&#45;Idf code   13":#_bookmark42 "Train vectors   14":#_bookmark44 "Sklearn Library   14":#_bookmark48 "Tf&#45;Idf Model   15":#_bookmark50 "Parameters   15":#_bookmark53 "Implementing model   16":#_bookmark58 "Accuracy   17":#_bookmark60</em>

</blockquote>

h1(#innova-bi̇li̇şi̇m-çözümleri̇-a.ş). INNOVA BİLİŞİM ÇÖZÜMLERİ A.Ş

<blockquote>

Innova Bilişim Çözümleri A.Ş., since its establishment in 1999, has been one of the leading IT solutions companies in Turkey with its innovative solutions that provide competitive, cost and profitability advantages in the digital transformation journeys of institutions.

Innova provides services in many fields, especially in telecommunications, finance, banking, insurance, retail, energy, automotive, production, service, and various public sectors.

Innova, which has rich competencies in artificial intelligence technologies, big data, and data analytics, PayFlex Innova in the field of fintech solutions such as payment, loyalty, and collection, SkywaveIoT on the internet of things, LEGA in administrative and legal debt follow&#45; up, HICAMP in health informatics and hospital management, aviation technologies. Provides services in the field with AvioFlex brands.

The company also provides local and national product software, manageable services, outsourcing, and consultancy services. On the system integration side, it operates in areas such as hardware, Kiosk &amp; Digital Signage and infrastructure services, and third&#45;party products and services such as SAP, Business Intelligence, CRM, IT Governance, and Project Management.

</blockquote>

!{width:622px;height:338px;}media/image2.jpeg!

h1(#introduction). INTRODUCTION

bq. I have completed my summer internship in Innova Bilişim, Ankara, Turkey. Due to COVID&#45;19, I had to do my training remotely. Since I was in communication with my supervisor, this situation did not affect my internship negatively. After a meeting with my supervisor, he asked me to research some machine learning stuff such as word2vec and tf&#45;idf or how we can use them in our project. We were dealing with texts written in Turkish; that's why I had a little trouble finding the source. There are lots of models and sources in English but not for sources in Turkish. This project they gave me was planned to label some unlabeled data by using ML. Moreover, I have learned Python and developed a supervised learning model to mark the data with reasonable accuracy.



h1(#problem-statement). PROBLEM STATEMENT

<blockquote>

During my summer practice, I have worked on three different problems.

First of all, I had to manually label the unlabeled dataset of 158,000 results as much as I could. This process was the most tedious part of my internship because I had to read and understand the long text, and I had to label it. While doing this, I used a website created by an intern who came before me.

Afterward, I have built a database in PostgreSQL. I keep the data in the database. When I label a text, the program adds the labels automatically to the database.

Finally, I have created a supervised learning model in Jupyter Notebook. This part was the most challenging because I had no idea how to create a model before summer practice.

</blockquote>

h2(#labeling-data-manually). Labeling Data Manually

<blockquote>

The main purpose of this part was to categorize the raw data received from "www.sikayetvar.com":http://www.sikayetvar.com/ manually. Since Innova is a collaborator of Türk Telekom, we collect the complaints made on behalf of Türk Telekom through "www.sikayetvar.com.":http://www.sikayetvar.com/ The company gave me the dataset containing 158000 complaints. I manually divided about 4000 (3000 trained data and 1000 test data) data into categories using the website made by the previous intern

["Figure 1":#_bookmark7]. The main reason we did this is to ensure that we have correctly labeled data to use a supervised learning model.

</blockquote>

!{width:617px;height:270px;}media/image3.jpeg!

bq. _Figure 1__: website for labeling_



h3(#www.sikayetvar.com). "www.sikayetvar.com":http://www.sikayetvar.com/

bq. sikayetvar.com ["Figure 2":#_bookmark10] is a website that allows people to send their complaints about the products they buy, cargo operations, and services online to companies.



!{width:624px;height:280px;}media/image4.jpeg!

bq. _Figure 2__:_ _"www.sikayetvar.com":http://www.sikayetvar.com/ Türk Telekom page_



<ol start="2" style="list-style-type: decimal;">
<li>h2(#building-database). Building Database

<ol style="list-style-type: decimal;">
<li>h3(#postgresql). PostgreSQL
</li>
</ol>
</li>
</ol>

bq. PostgreSQL is a powerful, open&#45;source object&#45;relational database system with reliability, feature robustness, and performance. I install psycopg like any other Python package ["Figure 3":#_bookmark14].



!{width:468px;height:89px;}media/image5.jpeg!

<blockquote>

_Figure 3__: Installing PostgreSQL library_

After installation, I imported the library import psycopg2 and used it to take data from the database.

!{width:622px;height:327px;}media/image6.jpeg(Text Description automatically generated)!

_Figure 4__: Taking data from the database_

I take all data at once ["Figure 4":#_bookmark16].

!{width:626px;height:124px;}media/image7.jpeg(A picture containing calendar Description automatically generated)!

_Figure 5__: Saving data to the data frame_

</blockquote>

h5(#trained-data). Trained Data

bq. The data which you use to train an algorithm or machine learning model to predict the outcome. Out of the 158000 data given to me by the company, out of the 4000 data I have categorized as I mentioned above, I have reserved 3000 data for the training data and kept it in a data frame ["Figure 5":#_bookmark18].



h5(#test-data). Test Data

bq. Our test data, also known as raw data, was set to 1000 data from 4000 data.



h5(#comparison-data). Comparison Data

bq. Our comparison data is a data set whose categories we already know. Using this data, we can tell if the predictions are correct by comparing the result of the projections of our test data.



h2(#supervised-learning-algorithm). Supervised Learning Algorithm

<blockquote>

Supervised learning uses a training dataset to teach models to yield the desired output. This training dataset includes inputs and correct outputs, which allow the model to learn over time. The algorithm measures its accuracy through the loss function, adjusting until the error has been sufficiently minimized (IBM, 2020).

Supervised learning can be separated into two types of problems when data mining&#45; classification and regression. I used classification in my project.

</blockquote>

h3(#classification). Classification

bq. Classification uses an algorithm to assign test data to specific categories ["Figure 6":#_bookmark25] correctly.



!{width:252px;height:223px;}media/image8.png!

<blockquote>

_Figure 6__: Classification graph_

As you see in figure "[9":#_bookmark25], we also separate our train data into two categories, network&#95;içi, and network&#95;dışı. network&#95;içi problems generally include connection errors, cable problems, and device problems. On the other hand, network&#95;dışı problems typically have technical issues and order, internet transfer problems. We took it as one if the complaint is related to the network&#95;içi, and 0 if not ["Figure 7":#_bookmark27].

</blockquote>

!{width:356px;height:52px;}media/image9.png!!{width:336px;height:208px;}media/image10.png!

bq. _Figure 7__: Separated data_



h3(#text-pre-processing). Text Pre&#45;Processing

<blockquote>

We must first preprocess our dataset by eliminating punctuation and special characters, cleaning texts, deleting stop words, and applying lemmatization before going on to model construction. Python provides us with some libraries to do these operations on English texts such as;

from nltk.tokenize import word&#95;tokenize from nltk.corpus import stopwords

from nltk.tokenize import word&#95;tokenize from nltk.stem import SnowballStemmer from nltk.corpus import wordnet

from nltk.stem import WordNetLemmatizer.

In order to use these operations on Turkish texts, I had to use external libraries such as Zemberek. Zemberek is a natural language processing library that you can use for open&#45;source Turkish languages developed using Java programming language ["Figure 8":#_bookmark30].

</blockquote>

!{width:565px;height:57px;}media/image11.png!

<blockquote>

_Figure 8__: Implementing Zemberek library_

After that, I used this library to preprocess. Also, I have downloaded a stop word txt file for the Turkish language ["Figure 9":#_bookmark32].

</blockquote>

!{width:624px;height:68px;}media/image12.jpeg!

bq. _Figure 9__: Implementing stop word data_



!{width:619px;height:53px;}media/image13.jpeg!!{width:411px;height:435px;}media/image14.jpeg!

<blockquote>

_Figure 10__: Preprocessing functions_

!{width:600px;height:94px;}media/image15.png(Text Description automatically generated)!

I cleaned the text by using preprocessing functions. Firstly, I removed all capital words and punctuations. And then, I applied a stopword list to our text and removed all stop words in our text. Finally, I used the Zemberek library to lemmatize our text ["Figure 10":#_bookmark34].

After preprocessing, finally, we get our clean text ["Figure 11":#_bookmark36].

</blockquote>

!{width:450px;height:437px;}media/image16.png!

bq. _Figure 11__: Cleaned text_



h3(#vectorization). Vectorization

h4(#term-frequency-inverse-document-frequencies-tf-idf). Term Frequency&#45;Inverse Document Frequencies (tf&#45;idf)

bq. Traditional TF&#45;IDF (Term Frequency&#45;Inverse Document Frequency) feature weighting algorithm only uses word frequency information to measure the importance of feature items in the data set (Wu &amp; Yuan, 2018). It is directly proportional to the word's frequency of occurrence in the text and inversely proportional to the frequency of occurrence in the sentence.



h4(#word2vec). Word2Vec

<blockquote>

Word2Vec, proposed and supported by Google, is not a unique algorithm, but it consists of two learning models, Continuous Bag of Words (CBOW) and Skip&#45;gram (Ma &amp; Zhang, 2015). I also used word2vec in my project, but my word2vec model did not work very effectively.

We can convert our text input to numerical form using any of these methods, which will be utilized to develop the categorization model. As I mentioned above, I allocated %75 of the dataset for the trained data and %25 for the test data by using the code below ["Figure 12":#_bookmark41].

</blockquote>

!{width:624px;height:81px;}media/image17.jpeg!

<blockquote>

_Figure 12__: Splitting datasets_

The code for vectorization by using Tf&#45;Idf "[Figure 13":#_bookmark43].

</blockquote>

!{width:556px;height:112px;}media/image18.png!

<blockquote>

_Figure 13__: Tf&#45;Idf code_

As you see in "Figure 14":#_bookmark45,the left part coordinates of non&#45;zero values and in the right part, values at that point.

</blockquote>

!{width:239px;height:259px;}media/image19.png!

bq. _Figure_ _14:Train vectors_



h3(#ml-algorithm). ML Algorithm

h6(#logistic-regression). Logistic Regression

<blockquote>

Logistic regression permits the use of continuous or categorical predictors and provides the ability to adjust for multiple predictors. This makes logistic regression especially useful for analyzing observational data when adjustment is needed to reduce the potential bias resulting from differences in the groups being compared (LaValley, 2008).

I imported the logistic regression using Python's sklearn library ["Figure 15":#_bookmark49].

</blockquote>

!{width:622px;height:140px;}media/image20.jpeg!

<blockquote>

_Figure_ _15:Sklearn Library_

I implemented classification model using Logistic Regression ["Figure 16":#_bookmark51].

</blockquote>

!{width:463px;height:365px;}media/image21.png!

bq. _Figure_ _16:Tf&#45;Idf Model_



h6(#auc-area-under-the-curve). AUC (Area Under the Curve)

<blockquote>

The Area Under the ROC curve (AUC) is an aggregated metric that evaluates how well a logistic regression model classifies positive and negative outcomes at all possible cutoffs. Our AUC value is 0.96, very close to 1 it is considered an outstanding score ["Figure 17":#_bookmark54].

Except for AUC, all the measures may be calculated using the four parameters on the left "[1515":#_bookmark54].

</blockquote>

!{width:571px;height:143px;}media/image22.jpeg!

<blockquote>

_Figure 17__: Parameters_

True Positives (TP): These are correctly predicted positive values. True Negatives (TN): These are correctly predicted negative values.

False Positives (FP): When the predicted and the actual value do not match False Negatives (FN): When the expected and the actual value do not match

</blockquote>

h6(#precision). Precision

<blockquote>

The ratio of accurately predicted positive observations to total expected positive observations is known as precision.

Precision = TP/TP&#43;FP

</blockquote>

h6(#recall). Recall

<blockquote>

The ratio of accurately predicted positive observations to all observations in the actual class is known as recall.

Recall = TP/TP&#43;FN

</blockquote>

h6(#f1-score). F1&#45;Score

<blockquote>

The weighted average of Precision and Recall is the F1 Score. As a result, this score considers both false positives and false negatives.

F1 Score = 2&#42;(Recall &#42; Precision) / (Recall &#43; Precision)

Finally, we implement our Tf&#45;If model to our test data. However, we need to clean our text data before the implementation process ["Figure 18":#_bookmark59].

</blockquote>

!{width:622px;height:296px;}media/image23.jpeg!

<blockquote>

_Figure 18__: Implementing the model_

To check if our predictions were correct, I compared my final data with the comparison data whose values I already know ["Figure 19":#_bookmark61].

</blockquote>

!{width:532px;height:259px;}media/image24.png!

bq. _Figure 19__: Accuracy_



h1(#conclusion). CONCLUSION

bq. As I previously stated, my internship provided me with a variety of intriguing duties. I finished my summer practice after coping with some issues. This summer's practice provided me with entirely new talents that I can apply to future work prospects. I've always wanted to be a perfect computer engineer; I've reached a portion of my aim. Now I know Python and machine learning algorithms, which are utilized in every sector of the world. I learned about Python, supervised and unsupervised learning techniques, data processing, and software integrations in a nutshell.



h1(#references). REFERENCES

# "[15":#_bookmark54]Accuracy, Precision, Recall &amp; F1 Score: Interpretation of Performance Measures. "https://blog.exsilio.com/all/accuracy&#45;precision&#45;recall&#45;f1&#45;score&#45;interpretation&#45;of&#45; performance&#45;measures/":https://blog.exsilio.com/all/accuracy-precision-recall-f1-score-interpretation-of-performance-measures/
# IBM. (2020, August 19). _Supervised Learning_

bq. https:/"/www.ibm.com/cloud/learn/supervised&#45;learning":http://www.ibm.com/cloud/learn/supervised-learning



#3 "[9":#_bookmark25] "https://www.javatpoint.com/classification&#45;algorithm&#45;in&#45;machine&#45;learning":https://www.javatpoint.com/classification-algorithm-in-machine-learning
# LaValley, M. P. (2008). Logistic Regression. " https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.106.682658":https://www.ahajournals.org/doi/full/10.1161/CIRCULATIONAHA.106.682658
# Ma, L. &amp; Zhang, Y. (2015). _Using Word2Vec to process big text data._

bq. https://ieeexplore.ieee.org/abstract/document/7364114



#6 "[7":#_bookmark10] "https://www.sikayetvar.com/turk&#45;telekom":https://www.sikayetvar.com/turk-telekom
# The official website of Postgresql https://"www.postgresql.org":http://www.postgresql.org/
# Wu, H., &amp; Yuan, N. (2018). _An Improved TF&#45;IDF algorithm based on word frequency distribution information and category distribution information._

<blockquote>

9. "https://dl.acm.org/doi/abs/10.1145/3232116.3232152":https://dl.acm.org/doi/abs/10.1145/3232116.3232152

"10. [11":#_bookmark30] Zemberek Kütüphanesi ile Türkçe Metinlerde Kelime Köklerinin Bulunması. "https://melikebektas95.medium.com/zemberek&#45;kütüphanesi&#45;ile&#45;türkçe&#45;metinlerde&#45; kelime&#45;köklerinin&#45;bulunması&#45;6ddd3a875d5f":https://melikebektas95.medium.com/zemberek-kÃ¼tÃ¼phanesi-ile-tÃ¼rkÃ§e-metinlerde-kelime-kÃ¶klerinin-bulunmasÄ±-6ddd3a875d5f

</blockquote>

h1(#remote-internship-appendix-form). REMOTE INTERNSHIP APPENDIX FORM

h1(#section). !{width:685px;height:439px;}media/image25.png!
